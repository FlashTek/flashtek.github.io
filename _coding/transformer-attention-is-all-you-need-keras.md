---
title: "Transformer: Attention is all you need for Keras"
collection: coding
type: "python"
permalink: /coding/transformer-attention-is-all-you-need-keras
source: 'https://github.com/FlashTek/attention-is-all-you-need-keras'
excerpt: 'Implementation of the Transformer architecture described by Vaswani et al. in `Attention Is All You Need`.'
date: 2018-06-01
---
Implementation of the Transformer architecture described by Vaswani et al. in "Attention Is All You Need" using the [Keras Utility & Layer Collection (kulc)](https://github.com/FlashTek/keras-layer-collection).

<img src="https://github.com/FlashTek/attention-is-all-you-need-keras/raw/master/model.png" height="500">

This repository contains the code the create the model, train and evaluate it. Furthermore, it contains utility code to load a translation dataset (`en2de`) to run the experiments on it.
